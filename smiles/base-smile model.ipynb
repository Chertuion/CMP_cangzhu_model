{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 19:37:25.032578: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-26 19:37:25.046971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750937845.064051    2945 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750937845.069294    2945 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750937845.082850    2945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750937845.082867    2945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750937845.082869    2945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750937845.082870    2945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-26 19:37:25.087640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1750937884.320784    2945 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 33980 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
      "I0000 00:00:1750937884.322791    2945 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43590 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:14:00.0, compute capability: 8.6\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tf.Tensor(1.0745559, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    200\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    202\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[1;32m    203\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    694\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:208\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7f0265ba0440>, 'Connection to huggingface.co timed out. (connect timeout=10)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f0265ba0440>, 'Connection to huggingface.co timed out. (connect timeout=10)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1533\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1533\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1534\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[1;32m   1535\u001b[0m     )\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1450\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1450\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1451\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1452\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1453\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1454\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1455\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1456\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1457\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1458\u001b[0m )\n\u001b[1;32m   1459\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    287\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    288\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    289\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[1;32m    310\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:310\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f0265ba0440>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 29fdf93f-60b5-4503-a8bd-e762248727e3)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:470\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     hf_hub_download(\n\u001b[1;32m    471\u001b[0m         path_or_repo_id,\n\u001b[1;32m    472\u001b[0m         filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    473\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    474\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    475\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    476\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    477\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    478\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    479\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    480\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    481\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    482\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1009\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1013\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1014\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1015\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1018\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1019\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1020\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1021\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1024\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1025\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1115\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1648\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1652\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhead_call_error\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 创建 Pipeline 对象，并传递 device 参数\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m nlp \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 使用 Pipeline 对象进行预测\u001b[39;00m\n\u001b[1;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py:911\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 911\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    912\u001b[0m         hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1153\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1151\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1153\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1154\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1155\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:595\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:654\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    655\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    656\u001b[0m         configuration_file,\n\u001b[1;32m    657\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    658\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    659\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    660\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    661\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    662\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    663\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    664\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    665\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    666\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:312\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    255\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    313\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:543\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load the files, and couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find them in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# 定义 TensorFlow 2.x 兼容的损失函数\n",
    "labels = tf.constant([0, 1, 2])  # 示例标签\n",
    "logits = tf.random.uniform((3, 3))  # 示例 logits\n",
    "\n",
    "loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "print(\"Loss:\", loss)\n",
    "\n",
    "# 检查是否有 GPU 可用，并设置设备\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# 创建 Pipeline 对象，并传递 device 参数\n",
    "nlp = pipeline('sentiment-analysis', device=device)\n",
    "\n",
    "# 使用 Pipeline 对象进行预测\n",
    "result = nlp(\"This is a test sentence.\")\n",
    "print(\"Result:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.09522178024053574, 'token': 60, 'token_str': '##1', 'sequence': 'is1.'}, {'score': 0.05135482922196388, 'token': 66, 'token_str': '##2', 'sequence': 'is2.'}, {'score': 0.02444583550095558, 'token': 212, 'token_str': '##C1', 'sequence': 'isC1.'}, {'score': 0.017586102709174156, 'token': 147, 'token_str': '##c1ccccc1', 'sequence': 'isc1ccccc1.'}, {'score': 0.015086532570421696, 'token': 421, 'token_str': '##12', 'sequence': 'is12.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"fill-mask\", model=\"unikei/bert-base-smiles\")\n",
    "\n",
    "result = pipe(\"The chemical structure is [MASK].\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskedLMOutput(loss=None, logits=tensor([[[-4.3032, -2.4302, -4.7559,  ..., -3.2660, -3.0424, -3.9323],\n",
      "         [-4.2550, -0.9499, -5.6878,  ..., -2.9477, -1.3502, -2.4843],\n",
      "         [-2.8878, -1.0404, -4.8648,  ..., -1.7557, -0.9981, -1.3585],\n",
      "         ...,\n",
      "         [-3.5062, -1.9077, -5.6774,  ..., -3.1204, -1.7040, -2.4833],\n",
      "         [-6.9082, -3.7634, -5.5565,  ..., -3.2631, -3.8547, -4.1455],\n",
      "         [-6.5226, -5.1462, -3.7645,  ..., -5.3631, -4.9794, -6.0008]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"unikei/bert-base-smiles\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 示例用法\n",
    "inputs = tokenizer(\"The chemical structure is [MASK].\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_4744\\1900707474.py:4: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  model_dir = \"E:\\Microsoft VS Code\\hello-world\\cache\\models--unikei--bert-base-smiles\"\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, pipeline\n",
    "\n",
    "# 本地模型目录\n",
    "model_dir = \"E:\\Microsoft VS Code\\hello-world\\cache\\models--unikei--bert-base-smiles\"\n",
    "\n",
    "# 加载本地模型和分词器\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# 使用加载的模型和分词器创建 pipeline\n",
    "pipe = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "example = 'CC(=C1CCC(CC1)(C)O)C'\n",
    "tokens = tokenizer(example, return_tensors='pt')\n",
    "predictions = model(**tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.3821,  0.0593, -0.1914,  ..., -2.0613, -0.4603, -1.1894],\n",
      "         [-0.9418, -0.1656,  0.2671,  ..., -0.9770, -0.0633, -1.9062],\n",
      "         [ 1.1226, -0.4002,  0.3521,  ...,  0.1618, -0.1386,  1.8086],\n",
      "         ...,\n",
      "         [ 0.6186,  0.3017,  0.1241,  ..., -0.1342,  0.0974, -0.0602],\n",
      "         [ 0.4130, -1.1119,  0.2806,  ...,  0.0944, -0.5532, -0.3501],\n",
      "         [ 0.5375,  0.7749,  1.0559,  ..., -1.0184, -0.0626, -0.3657]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7910,  0.9982,  0.5162,  0.5645,  0.9931, -1.0000, -0.9679,  0.9552,\n",
      "         -0.9853,  0.9589, -0.9807,  0.9999,  0.5608, -0.9023,  0.3254,  0.9963,\n",
      "         -0.9993, -0.9995, -0.9986,  0.9893, -0.9805, -0.9412,  1.0000,  0.9999,\n",
      "         -0.9650,  0.9021, -0.9906,  0.9998,  0.9825, -0.9002, -0.0313,  0.9987,\n",
      "         -0.9999,  0.9993, -0.9979, -0.6498, -0.9986,  0.9922, -1.0000,  0.6821,\n",
      "          0.1280, -0.9983, -0.9985,  0.4523,  0.9548,  0.8372, -0.9949,  0.9992,\n",
      "         -0.8152, -0.9504,  0.9233,  0.9772,  0.9706, -0.9996,  0.9951,  0.9335,\n",
      "          0.9998,  0.4958, -0.9636, -0.9993, -0.4236,  0.9906, -0.8122,  0.8259,\n",
      "         -0.6304,  0.9495, -0.9998,  0.8438,  0.8735,  0.9972,  0.9967, -0.5223,\n",
      "          0.9734, -0.9767,  0.8727,  0.9219, -0.8907, -0.9994,  0.9975,  0.9954,\n",
      "          0.8217,  0.9813,  0.8811,  0.9990, -0.9982, -0.9557, -0.9945, -0.1240,\n",
      "          0.5805,  0.9986,  0.9990, -0.9980,  0.8054, -0.9962,  0.9970,  0.9105,\n",
      "          0.9781,  0.9947, -0.9689,  0.9968,  1.0000, -0.9918, -0.9983, -0.9989,\n",
      "          0.8950, -0.9991,  0.9992, -0.8593, -0.9647, -0.6932, -0.9995, -0.8731,\n",
      "          0.6549, -0.9997, -0.9844, -0.9018, -0.9893, -0.9721, -0.6195,  0.6840,\n",
      "          0.9653, -0.9998, -0.9830,  0.8567, -0.9991, -0.9945, -0.9942, -0.9987,\n",
      "         -0.8455,  0.9993,  0.9969, -0.9773,  0.9999,  0.9446, -0.9901,  0.9846,\n",
      "         -0.9995, -0.1405,  0.9344, -0.4566,  0.9992, -0.9883,  0.8935,  0.9972,\n",
      "          0.9795, -0.9471,  0.9444, -0.9386, -0.9981, -0.9994, -1.0000,  0.9651,\n",
      "          0.9739, -0.9875,  0.8699,  0.9993,  0.9994,  0.9557, -0.6019,  0.9648,\n",
      "          0.6508,  0.9806, -0.9633,  0.9558, -0.9883, -0.9997, -0.9367, -0.9662,\n",
      "         -0.9879, -0.9997,  0.9948, -0.9992, -0.9739, -0.9458, -0.9451,  0.9144,\n",
      "          0.9966,  0.9817,  0.9833,  0.9295,  1.0000, -0.6115,  0.9802,  0.4455,\n",
      "          0.7668, -0.9995,  0.7733, -0.8827, -0.9991, -0.8302, -0.8424,  0.9473,\n",
      "         -0.9886,  0.6797,  0.6204,  0.8177,  0.9167,  0.8128,  0.8469, -0.9969,\n",
      "          0.9989,  0.8881, -0.9991, -0.9994, -0.8558, -0.8194,  0.9279, -0.9474,\n",
      "         -0.9854,  0.9689, -0.9997, -0.9983, -0.9843,  0.2633, -0.8399, -0.8064,\n",
      "          0.9987,  0.9846,  0.9430, -0.9880,  1.0000, -0.9841, -0.9990, -0.8640,\n",
      "         -0.9979,  0.9163,  0.9979, -0.9998, -0.8630, -0.7422,  0.9035, -0.7474,\n",
      "          0.7429, -0.9756,  0.7962,  0.9832,  0.9982,  0.9991,  0.9469, -0.9969,\n",
      "          0.5806,  0.9687,  0.9999,  0.5612,  0.9999, -0.9670,  0.9994,  0.8751,\n",
      "         -0.6081, -0.9949,  0.9995, -0.9993, -0.8012,  0.9933,  0.9992, -0.9991,\n",
      "          0.9990,  0.9996,  0.9505, -0.9963,  0.9767, -0.5401,  0.7324,  0.7818,\n",
      "         -0.9856, -0.9573,  0.9754,  0.9958,  0.9892, -0.9942,  0.9960,  0.8151,\n",
      "         -0.9998, -0.9981, -0.9850,  0.9667, -0.9875,  0.8640, -0.9677,  0.9924,\n",
      "         -0.9588, -0.8726, -0.9618, -0.9460,  0.7362, -0.9723, -0.7751, -0.9454,\n",
      "          0.9993,  0.8828, -0.6301, -0.7683, -0.9798, -0.7620, -0.9996,  0.9755,\n",
      "          0.9709, -0.9947,  0.9898,  0.9919,  0.9973,  0.8937, -0.6852, -0.9992,\n",
      "          0.9452,  0.7104, -0.9023,  0.9998,  0.9022,  0.9968, -0.8535, -0.9982,\n",
      "         -0.9999,  0.9597,  0.9501, -0.9621, -0.9375,  0.3667,  0.7262, -0.9937,\n",
      "          0.9970, -0.9740, -0.7825,  0.9996, -0.6465, -0.9996, -0.9995, -0.6820,\n",
      "          0.9133,  0.6767, -0.3611,  0.9982,  0.9624,  0.9986,  0.7573,  0.9994,\n",
      "          0.9243,  0.9453,  0.9999, -0.9967, -0.8720, -0.9976,  0.9996,  0.9978,\n",
      "          0.9997,  0.9516,  0.9969, -0.9961,  0.7918,  0.9759, -0.7177,  0.7562,\n",
      "          0.8961,  0.9697,  0.9570,  0.9984, -0.9915,  0.9997,  0.9965,  0.8791,\n",
      "          0.8960, -0.9858,  0.6869,  0.8670, -0.8326, -0.9990,  0.8949, -0.8591,\n",
      "          0.9997, -0.9369, -0.9615, -0.8644, -0.6783,  0.9999, -0.9998,  0.9861,\n",
      "          0.9718,  0.9981, -0.9896,  0.9978,  0.9990,  0.9997,  0.9625, -0.9998,\n",
      "         -0.9644, -0.9995, -0.8790, -0.9993,  0.9963, -0.9971, -0.9992,  0.9450,\n",
      "         -0.7213, -0.9519, -0.9998,  0.9996,  0.8082,  0.8471,  0.9998, -0.9872,\n",
      "          0.8212, -0.9292, -0.9853,  0.9874, -0.9987, -0.3942, -0.9979, -0.8770,\n",
      "          0.6302, -0.9904,  0.9992,  0.9057,  0.9734,  0.9991,  0.9093, -0.9993,\n",
      "         -0.9853, -0.9851, -0.9800, -0.7828, -0.9993,  0.8048, -0.9489, -0.9989,\n",
      "         -0.9445,  0.9073, -0.9997,  0.9997, -0.6046, -0.8580, -0.7790,  0.8526,\n",
      "          0.9972,  0.9995, -0.8220,  0.9986,  0.9288,  0.9982, -0.0214, -0.7099,\n",
      "          0.8786, -0.2322, -0.9999, -0.9982,  0.9683,  0.9857, -0.8410, -0.6531,\n",
      "         -0.7315,  0.9989,  0.9975, -0.9677, -0.9369, -0.9962, -0.9969,  0.9706,\n",
      "          0.9830, -0.9098, -0.9932,  0.9575,  0.6775,  0.9566,  0.9996,  0.9994,\n",
      "         -0.9921,  0.9928, -0.9989,  0.9810, -0.7955,  0.9657,  0.8684, -0.9910,\n",
      "         -0.5694,  0.9335, -0.9993, -0.9999,  0.8650,  0.8981, -0.9674, -0.8482,\n",
      "          0.7646, -0.9866,  0.9979, -0.7495,  0.9998,  0.9998,  0.9979, -0.9663,\n",
      "         -0.5114, -0.9886, -0.9847, -0.9999, -0.9956, -0.9998, -0.7000, -0.9995,\n",
      "         -0.9943, -0.9985, -0.9986,  0.9678, -0.3102, -0.9984,  0.9991,  0.6377,\n",
      "          0.9963,  0.9989,  0.7082,  0.9867, -0.9419,  0.9893, -0.9636,  0.7840,\n",
      "          0.8296,  0.9993, -0.5786, -0.9415,  0.9752,  0.8513, -0.9986,  0.9998,\n",
      "          0.9984,  0.9988,  0.9999, -0.9900, -0.9948, -0.8826, -0.9707,  0.9999,\n",
      "         -0.7492,  0.7339,  0.9631, -0.8352, -0.9998,  0.8823, -0.9875,  0.9181,\n",
      "         -0.9998, -0.9941,  0.9472,  0.8855,  0.9996,  0.9998,  0.7425,  0.9115,\n",
      "         -0.9513,  0.9667, -0.9997,  0.9995,  0.9740,  0.9573,  1.0000, -0.9250,\n",
      "         -0.4410, -0.9981, -0.9494, -0.8091, -0.9938, -0.9972,  0.9996,  0.9999,\n",
      "          0.9195, -0.9988, -0.9992,  0.9996, -0.9958,  1.0000, -0.8097,  0.8539,\n",
      "         -0.8119,  0.8456, -0.7931, -0.9971,  0.9971, -0.8711, -0.9865, -0.9997,\n",
      "          0.9984, -0.9942, -0.9494,  0.8841, -0.9485, -0.9297,  0.9993, -0.7478,\n",
      "          0.5879,  0.9414,  0.9485, -0.9951, -0.6257,  0.7331,  1.0000, -0.9995,\n",
      "         -0.8834, -0.8563,  0.9556, -0.9997, -0.9948, -0.9774, -0.9501,  0.9999,\n",
      "         -0.7751,  0.9999, -0.6694,  0.9991,  0.9214,  0.9835,  0.9996,  0.9996,\n",
      "         -0.8783,  0.7090, -0.8799, -0.9941, -0.9947, -0.9938, -0.9999,  0.8887,\n",
      "         -0.9989, -0.8837, -0.9792, -0.9836,  0.9892,  0.8600,  0.9726,  0.9986,\n",
      "         -0.9999,  0.7985,  0.9987, -0.9842,  0.9705,  0.9052, -0.9991, -0.7734,\n",
      "          0.9999, -0.7774,  0.9421, -0.7789, -0.9988, -0.5484,  0.9676, -0.9986,\n",
      "          0.9973,  0.9967, -0.9239, -0.9874, -0.9927,  0.8134,  0.9793,  0.9284,\n",
      "          0.9995, -0.9450,  0.7950,  0.8434, -0.9838, -0.9545,  0.9991, -1.0000,\n",
      "         -0.7336,  0.9996,  0.9973, -0.9497,  0.7646, -0.9991, -0.9992,  0.9995,\n",
      "         -0.9999,  0.9888,  0.6886,  0.7962,  0.8895, -0.9995, -0.9735,  0.6907,\n",
      "         -0.8662, -0.9997,  1.0000,  0.9996, -0.9154,  0.9963,  0.9979, -0.9991,\n",
      "          0.9984,  0.9865,  0.9706,  0.9973,  0.9997, -0.9996, -0.9985, -0.9452,\n",
      "         -0.9990, -0.7147, -0.8982,  0.8155, -1.0000, -0.7998,  0.9930, -0.9853,\n",
      "          0.9990,  0.9970, -0.9977, -0.5622, -0.8914,  0.8672,  0.8218,  0.8915,\n",
      "         -0.9988,  0.8668,  0.9732,  0.9918, -0.9999,  0.5447,  0.6008, -0.8841,\n",
      "          0.9991, -0.9960,  0.4838, -0.9971,  0.9998, -0.9350, -0.8084, -0.9163,\n",
      "          0.9987,  0.9959, -0.9998,  0.9148,  0.9989,  0.9056,  0.9999,  0.7851,\n",
      "         -0.9261, -0.9973, -0.9552,  0.9115,  0.9999,  0.9973, -0.9973, -0.9999,\n",
      "          0.9990,  0.9996, -0.9996,  0.9991,  0.9814,  0.7837,  0.9992,  0.8452,\n",
      "          0.9989,  0.9061, -0.9903,  0.2583,  0.9987,  0.9764, -0.9919, -0.9506,\n",
      "         -0.7560, -0.9545, -0.8275,  0.9999, -0.9962, -0.9822,  0.9300,  0.9957,\n",
      "          0.9983, -0.9415,  0.9991,  0.8349, -0.9478,  0.9912,  0.9979, -0.9989]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "# 检查点\n",
    "checkpoint = 'unikei/bert-base-smiles'\n",
    "\n",
    "# 加载分词器和模型\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "model = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "# 示例化学结构\n",
    "example = 'O=C([C@@H](c1ccc(cc1)O)N)N[C@@H]1C(=O)N2[C@@H]1SC([C@@H]2C(=O)O)(C)C'\n",
    "\n",
    "# 分词并转换为张量\n",
    "tokens = tokenizer(example, return_tensors='pt')\n",
    "\n",
    "# 获取模型预测\n",
    "predictions = model(**tokens)\n",
    "\n",
    "# 输出预测结果\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.3891, -0.3446, -0.3292, -0.1169, -0.4191, -0.2149,  1.1780,\n",
      "           1.2397, -0.7469,  1.0494],\n",
      "         [ 0.0408, -1.1103,  0.4044, -1.1863, -0.8673,  0.3298,  0.4088,\n",
      "          -0.3032,  0.4354, -0.3469],\n",
      "         [ 0.8175,  0.5906, -0.2215,  0.7961,  0.2008, -1.4717,  0.8731,\n",
      "          -1.1413,  2.0235,  0.0130],\n",
      "         [ 0.0986, -1.0642,  0.3398, -1.2157, -0.9237,  0.3049,  0.4962,\n",
      "          -0.3134,  0.2976, -0.5091],\n",
      "         [ 0.8261,  0.7386, -0.9689,  0.9090, -0.7139, -0.5192,  1.1083,\n",
      "           1.2646,  3.3352,  0.6968],\n",
      "         [ 0.8821,  0.7393, -0.9774,  0.9404, -0.5289, -0.4828,  0.9750,\n",
      "           1.1991,  3.3168,  0.6071],\n",
      "         [-0.0262,  0.9493,  0.8379,  0.3171,  0.6171,  0.7090,  0.7168,\n",
      "           0.5373, -2.3123, -0.1886],\n",
      "         [ 0.7953, -0.0645, -0.7876, -0.1184,  1.6648,  0.0772, -1.6060,\n",
      "          -0.3466,  0.1176, -1.0892],\n",
      "         [ 0.2443,  0.4348,  2.7563, -0.2338, -0.0605, -2.6511, -0.6970,\n",
      "           0.2661,  1.0860,  0.8454],\n",
      "         [ 0.8283,  0.5514, -0.2584,  0.8165,  0.1485, -1.5005,  0.9031,\n",
      "          -1.1111,  2.0555, -0.0144]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "checkpoint = 'unikei/bert-base-smiles'\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "model = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "example = 'C[C@@H]1CC[C@@H]2[C@]13C=CC[C@]3(CC2(C)C)C'\n",
    "\n",
    "tokens = tokenizer(example, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(**tokens)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(str(predictions))\n",
    "\n",
    "print(predictions.last_hidden_state[:, :10, :10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "# 检查点\n",
    "checkpoint = 'unikei/bert-base-smiles'\n",
    "\n",
    "# 加载分词器和模型\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "model = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "# 从CSV文件读取输入数据\n",
    "input_file = '/data/home/wxl22/changzu_ans/smiles/76成分smiles号.csv'  # 你的输入文件路径\n",
    "input_data = pd.read_csv(input_file)\n",
    "\n",
    "# 假设CSV文件有一列名为'example'，包含化学结构字符串\n",
    "examples = input_data['example'].tolist()\n",
    "\n",
    "# 创建一个空列表存储预测结果\n",
    "all_predictions = []\n",
    "\n",
    "for example in examples:\n",
    "    # 分词并转换为张量\n",
    "    tokens = tokenizer(example, return_tensors='pt')\n",
    "\n",
    "    # 获取模型预测\n",
    "    with torch.no_grad():\n",
    "        predictions = model(**tokens)\n",
    "\n",
    "    # 获取分词后的token和特征值\n",
    "    token_ids = tokens['input_ids'].squeeze().tolist()\n",
    "    tokens_str = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    features = predictions.last_hidden_state.squeeze().tolist()\n",
    "\n",
    "    # 截断token和特征以适应DataFrame的大小\n",
    "    truncated_tokens_str = tokens_str[:512]  # BERT的输入限制为512个token\n",
    "    truncated_features = features[:512]\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(truncated_features, index=truncated_tokens_str)\n",
    "\n",
    "    # 将DataFrame转换为字符串并添加到列表中\n",
    "    all_predictions.append(df.to_string())\n",
    "\n",
    "# 将所有预测结果写入文本文件\n",
    "output_file = '/data/home/wxl22/changzu_ans/smiles/GCMS-output.txt'  # 你的输出文件路径\n",
    "with open(output_file, 'w') as f:\n",
    "    for idx, prediction in enumerate(all_predictions):\n",
    "        f.write(f\"Example {idx + 1}:\\n\")\n",
    "        f.write(prediction)\n",
    "        f.write(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "local_path = '/data/home/wxl22/changzu_ans/bert-base-smiles'\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(local_path, local_files_only=True)\n",
    "model = BertModel.from_pretrained(local_path, local_files_only=True)\n",
    "\n",
    "example = 'O=C([C@@H](c1ccc(cc1)O)N)N[C@@H]1C(=O)N2[C@@H]1SC([C@@H]2C(=O)O)(C)C'\n",
    "tokens = tokenizer(example, return_tensors='pt')\n",
    "outputs = model(**tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "local_path = '/data/home/wxl22/changzu_ans/bert-base-smiles'\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(local_path, local_files_only=True)\n",
    "model = BertModel.from_pretrained(local_path, local_files_only=True)\n",
    "\n",
    "# 从CSV文件读取输入数据\n",
    "input_file = '/data/home/wxl22/changzu_ans/smiles/72smiles.csv'  # 你的输入文件路径\n",
    "input_data = pd.read_csv(input_file)\n",
    "\n",
    "# 假设CSV文件有一列名为'example'，包含化学结构字符串\n",
    "examples = input_data['SMILES'].tolist()\n",
    "\n",
    "# 创建一个空列表存储预测结果\n",
    "all_predictions = []\n",
    "\n",
    "for example in examples:\n",
    "    # 分词并转换为张量\n",
    "    tokens = tokenizer(example, return_tensors='pt')\n",
    "\n",
    "    # 获取模型预测\n",
    "    with torch.no_grad():\n",
    "        predictions = model(**tokens)\n",
    "\n",
    "    # 获取分词后的token和特征值\n",
    "    token_ids = tokens['input_ids'].squeeze().tolist()\n",
    "    tokens_str = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    features = predictions.last_hidden_state.squeeze().tolist()\n",
    "\n",
    "    # 只保留前10个token的前10个特征值\n",
    "    truncated_features = [feature[:10] for feature in features[:10]]\n",
    "    truncated_tokens_str = tokens_str[:10]\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(truncated_features, index=truncated_tokens_str)\n",
    "\n",
    "    # 将DataFrame转换为字符串并添加到列表中\n",
    "    all_predictions.append(df.to_string())\n",
    "\n",
    "# 将所有预测结果写入文本文件\n",
    "output_file = '/data/home/wxl22/changzu_ans/smiles/shortGCMS-output.txt'  # 你的输出文件路径\n",
    "with open(output_file, 'w') as f:\n",
    "    for idx, prediction in enumerate(all_predictions):\n",
    "        f.write(f\"Example {idx + 1}:\\n\")\n",
    "        f.write(prediction)\n",
    "        f.write(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
